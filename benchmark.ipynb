{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5702150,"sourceId":9395341,"sourceType":"datasetVersion"},{"sourceId":196802417,"sourceType":"kernelVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"drl","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Benchmark DRL with Q-Network\n\n```BibTeX\n@article{theate2021application,\n  title={An application of deep reinforcement learning to algorithmic trading},\n  author={Th{\\'e}ate, Thibaut and Ernst, Damien},\n  journal={Expert Systems with Applications},\n  volume={173},\n  pages={114632},\n  year={2021},\n  publisher={Elsevier}\n}\n```","metadata":{}},{"cell_type":"markdown","source":"## Setup Notebook","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport sys\nwarnings.filterwarnings(\"ignore\")\n\nINSTALL_DEPS = False\nif INSTALL_DEPS:\n    # If Kaggle or Colab, you have to manage these. If local, install requirements.txt\n    %pip install yfinance==0.2.43\n    # %pip install scipy==1.14.1\n    # %pip install statsmodels==0.14.2\n    # %pip install tabulate==0.9.0\n    # %pip install torch==2.4.1\n    # %pip install tqdm==4.66.5\n    # %pip install gym==0.26.1\n    # %pip install numpy==2.1.1\n    # %pip install pandas==2.2.2\n\nIN_KAGGLE = IN_COLAB = False\ntry:\n    # https://www.tensorflow.org/install/pip#windows-wsl2\n    import google.colab\n    from google.colab import drive\n\n    drive.mount(\"/content/drive\")\n    DATA_PATH = \"/drive/input/drl-dataset-quant\"\n    IN_COLAB = True\n    print(\"Colab!\")\nexcept:\n    IN_COLAB = False\nif \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ and not IN_COLAB:\n    print(\"Running in Kaggle...\")\n    for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n    DATA_PATH = \"/kaggle/input/drl-dataset-quant\"\n    sys.path.insert(1, \"/kaggle/usr/lib/drlutil\")\n    IN_KAGGLE = True\n    print(\"Kaggle!\")\nelif not IN_COLAB:\n    IN_KAGGLE = False\n    DATA_PATH = \"./data/\"\n    print(\"running localhost!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from drlutil import TradingSimulator","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Experiment Parameters","metadata":{}},{"cell_type":"code","source":"simulator = TradingSimulator()\nstrategy = \"TDQN\"\nstock = \"Tesla\"\n\nfeatures=['Close', 'Low', 'High', 'Volume']\nmoney=100000.\nstateLength = 30\nobservationSpace = 1 + ((stateLength- 1)*len(features))\nactionSpace = 2\nbounds = [1, 30]\nstep = 1\nnumberOfEpisodes = 50\nstartingDate = '2012-1-1'\nendingDate = '2020-1-1'\nsplitingDate = '2018-1-1'\npercentageCosts = [0, 0.1, 0.2]\ntransactionCosts = percentageCosts[1]/100\n\n\nprint(observationSpace)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run Experiments","metadata":{}},{"cell_type":"markdown","source":"## Test Selected Stock and Strategy","metadata":{}},{"cell_type":"code","source":"\nsimulator.simulateNewStrategy(strategy,\n                              stock,\n                              startingDate=startingDate,\n                              endingDate=endingDate,\n                              splitingDate=splitingDate,\n                              rendering=True,\n                              saveStrategy=False,\n                              data_dir=DATA_PATH,\n                              money=money,\n                              observationSpace=observationSpace,\n                              actionSpace=actionSpace,\n                              stateLength=stateLength,\n                              bounds=bounds,\n                              step=step,\n                              numberOfEpisodes=numberOfEpisodes,\n                              transactionCosts=transactionCosts,\n                              features=features)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Experiment Results","metadata":{}},{"cell_type":"markdown","source":"| Performance Indicator           | Training  | Testing  | B&H      | S&H      | TF      | MR      | TDQN    |\n|----------------------------------|-----------|----------|----------|----------|---------|---------|---------|\n| Profit & Loss (P&L)              | 11686926  | -9801    | 29847    | -29847   | 73301   | 8600    | 98      |\n| Annualized Return                | 36.25%    | 8.03%    | 24.11%   | -7.38%   | 100.00% | 19.02%  | 12.80%  |\n| Annualized Volatility            | 45.32%    | 51.64%   | 53.14%   | 46.11%   | 52.70%  | 58.05%  | 52.09%  |\n| Sharpe Ratio                     | 1.983     | 0.162    | 0.508    | -0.154   | 0.987   | 0.358   | 0.261   |\n| Sortino Ratio                    | 3.196     | 0.204    | 0.741    | -0.205   | 1.229   | 0.539   | 0.359   |\n| Maximum Drawdown                 | 15.31%    | 60.36%   | 52.83%   | 54.09%   | 79.91%  | 65.31%  | 58.95%  |\n| Maximum Drawdown Duration        | 47 days   | 95 days  | 205 days | 144 days | 229 days| 159 days| 331 days|\n| Profitability                    | 54.82%    | 46.38%   | 100.00%  | 0.00%    | 34.38%  | 67.65%  | 38.18%  |\n| Ratio Average Profit/Loss        | 3.082     | 1.112    | âˆž        | 0.00     | 0.534   | 0.496   | 1.621   |\n\nTraining time: 19:08mins\n","metadata":{}}]}